{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10cbf4e4",
   "metadata": {},
   "source": [
    "# Web Scraping- Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132f563a",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data. This task will be done in following steps:\n",
    "\n",
    "1.First get the webpage https://www.naukri.com/\n",
    "2.Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3.Then click the search button.\n",
    "4.Then scrape the data for the first 10 jobs results you get.\n",
    "5.Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb943e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\vikrant\\anaconda3\\lib\\site-packages (4.4.3)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\vikrant\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\vikrant\\anaconda3\\lib\\site-packages (from selenium) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\vikrant\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\vikrant\\anaconda3\\lib\\site-packages (from selenium) (0.21.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\vikrant\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.14.6)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\vikrant\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.2.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\vikrant\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: idna in c:\\users\\vikrant\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.2)\n",
      "Requirement already satisfied: outcome in c:\\users\\vikrant\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\vikrant\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\vikrant\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\vikrant\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\vikrant\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.1.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\vikrant\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\vikrant\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n"
     ]
    }
   ],
   "source": [
    "#First install the Selenium\n",
    "\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8fcc75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all required libraries \n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e09f627",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets connect with web driver\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\vikrant\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6c1b105",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53545217",
   "metadata": {},
   "outputs": [],
   "source": [
    "#onpening the naukri.com website on automated chrome window\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76ff2dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding element for job search bar\n",
    "Designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "Designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa9d416a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering Location banglore in location search bar\n",
    "#search_field_loc=driver.find_element_by_class_name('suggestor-input') #here for location same class name came so we have to use absolute xpath\n",
    "#search_field_loc.send_keys('banglore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22bcc605",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_field_loc=driver.find_element(By.XPATH,'/html/body/div/div[2]/div[3]/div/div/div[5]/div/div/div/input')\n",
    "search_field_loc.send_keys('banglore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f35f0bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33370845",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "454c553f",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a173f88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping job location\n",
    "location_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66fa4369",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping company name\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d083c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping job experience\n",
    "experience_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]//span')\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "650c40da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aaf22b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Titiel</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business &amp; Data Analyst- Assistant Manager</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru</td>\n",
       "      <td>State Street</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sr. Business Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Infometry</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sr Clinical Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>LabCorp</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Manager / Senior Manager - Data Analyst</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>Huquo Consulting Pvt. Ltd</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Analyst(Power BI/Python)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Societe Generale</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sr. Data Analyst</td>\n",
       "      <td>Bhopal, Indore, New Delhi, Pune, Bangalore Rur...</td>\n",
       "      <td>Netlink Software</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Business Analyst - Data Strategy</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Capco</td>\n",
       "      <td>9-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DATA Analyst- Immediate Joining</td>\n",
       "      <td>Bangalore/Bengaluru(Cox Town)</td>\n",
       "      <td>ADVISETREE CONSULTING PRIVATE LIMITED</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru(Old Madras Road)</td>\n",
       "      <td>KrazyBee</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Qualitest India Private Limited</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Job Titiel  \\\n",
       "0  Business & Data Analyst- Assistant Manager   \n",
       "1                   Sr. Business Data Analyst   \n",
       "2                    Sr Clinical Data Analyst   \n",
       "3     Manager / Senior Manager - Data Analyst   \n",
       "4        Senior Data Analyst(Power BI/Python)   \n",
       "5                            Sr. Data Analyst   \n",
       "6            Business Analyst - Data Strategy   \n",
       "7             DATA Analyst- Immediate Joining   \n",
       "8                         Senior Data Analyst   \n",
       "9                         Senior Data Analyst   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0        Hyderabad/Secunderabad, Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5  Bhopal, Indore, New Delhi, Pune, Bangalore Rur...   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                      Bangalore/Bengaluru(Cox Town)   \n",
       "8               Bangalore/Bengaluru(Old Madras Road)   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                            Company Name Experience Required  \n",
       "0                           State Street             1-3 Yrs  \n",
       "1                              Infometry             4-6 Yrs  \n",
       "2                                LabCorp             2-5 Yrs  \n",
       "3              Huquo Consulting Pvt. Ltd             2-7 Yrs  \n",
       "4                       Societe Generale             3-7 Yrs  \n",
       "5                       Netlink Software             3-6 Yrs  \n",
       "6                                  Capco            9-11 Yrs  \n",
       "7  ADVISETREE CONSULTING PRIVATE LIMITED             3-5 Yrs  \n",
       "8                               KrazyBee             3-6 Yrs  \n",
       "9        Qualitest India Private Limited             5-8 Yrs  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Job Titiel':job_title,'Job Location':job_location,'Company Name':company_name,'Experience Required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccbce2c",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data. This task will be done in following steps:\n",
    "\n",
    "1.First get the webpage https://www.naukri.com/\n",
    "2.Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3.Then click the search button.\n",
    "4.Then scrape the data for the first 10 jobs results you get.\n",
    "5.Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf2a73ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75c62125",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef187e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding element for job search bar\n",
    "Designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "Designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7ecd8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[3]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d5917fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "680a4e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "311645a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e51699ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "611a30d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2eb184c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]//span')\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6af13c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lead ML Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data scientist _Tata Consultancy Services(Tcs)</td>\n",
       "      <td>Bangalore/Bengaluru, Kochi/Cochin, Indore, New...</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Job||Job Opening For AI Technologist - Data Sc...</td>\n",
       "      <td>Bangalore/Bengaluru, New Delhi, Hyderabad/Secu...</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hiring For DATA Scientist @ NTT DATA Business ...</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>NTT DATA Business Solutions Private Limited</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tcs Hiring For Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Chennai, Mumbai (All Areas)</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Manager - EmTech - Machine Learning - P&amp;T</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>PwC</td>\n",
       "      <td>5-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Urgent Job Opening For AI Practitioner - Data ...</td>\n",
       "      <td>Bangalore/Bengaluru, Kochi/Cochin, New Delhi, ...</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>11-20 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist Lead_Tata Consultancy Services(...</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "      <td>8-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune</td>\n",
       "      <td>CitiusTech</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                                  Lead ML Scientist   \n",
       "1                   Analystics & Modeling Specialist   \n",
       "2     Data scientist _Tata Consultancy Services(Tcs)   \n",
       "3  Job||Job Opening For AI Technologist - Data Sc...   \n",
       "4  Hiring For DATA Scientist @ NTT DATA Business ...   \n",
       "5                      Tcs Hiring For Data Scientist   \n",
       "6   Senior Manager - EmTech - Machine Learning - P&T   \n",
       "7  Urgent Job Opening For AI Practitioner - Data ...   \n",
       "8  Data Scientist Lead_Tata Consultancy Services(...   \n",
       "9                   Assistant Manager - Data Science   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0                        Bangalore/Bengaluru, Mumbai   \n",
       "1  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...   \n",
       "2  Bangalore/Bengaluru, Kochi/Cochin, Indore, New...   \n",
       "3  Bangalore/Bengaluru, New Delhi, Hyderabad/Secu...   \n",
       "4  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...   \n",
       "5   Bangalore/Bengaluru, Chennai, Mumbai (All Areas)   \n",
       "6  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...   \n",
       "7  Bangalore/Bengaluru, Kochi/Cochin, New Delhi, ...   \n",
       "8  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...   \n",
       "9                  Bangalore/Bengaluru, Mumbai, Pune   \n",
       "\n",
       "                                  Company Name Experience Required  \n",
       "0                            Fractal Analytics            6-10 Yrs  \n",
       "1                                    Accenture             6-8 Yrs  \n",
       "2              TATA CONSULTANCY SERVICES (TCS)            9-14 Yrs  \n",
       "3                                        Wipro            5-10 Yrs  \n",
       "4  NTT DATA Business Solutions Private Limited             4-9 Yrs  \n",
       "5              TATA CONSULTANCY SERVICES (TCS)             3-8 Yrs  \n",
       "6                                          PwC            5-12 Yrs  \n",
       "7                                        Wipro           11-20 Yrs  \n",
       "8              TATA CONSULTANCY SERVICES (TCS)            8-12 Yrs  \n",
       "9                                   CitiusTech             5-9 Yrs  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Job Title':job_title,'Job Location':job_location,'Company Name':company_name,'Experience Required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8374b33",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage: You have to use the location and salary filter. You have to scrape data for “Data Scientist” designation for first 10 job results. You have to scrape the job-title, job-location, company name, experience required. The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs The task will be done as shown in the below steps:\n",
    "\n",
    "1.first get the webpage https://www.naukri.com/\n",
    "2.Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3.Then click the search button.\n",
    "4.Then apply the location filter and salary filter by checking the respective boxes\n",
    "5.Then scrape the data for the first 10 jobs results you get.\n",
    "6.Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3a3f5196",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "38cc08f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ebbd8f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f801b73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[3]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Delhi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1acccd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "1c3f486b",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ecbe1a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "198d1769",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2abf0a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "cfb228a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]//span')\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0d1373d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data scientist _Tata Consultancy Services(Tcs)</td>\n",
       "      <td>New Delhi, Kochi/Cochin, Indore, Hyderabad/Sec...</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Job||Job Opening For AI Technologist - Data Sc...</td>\n",
       "      <td>New Delhi, Hyderabad/Secunderabad, Pune, Chenn...</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hiring For DATA Scientist @ NTT DATA Business ...</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...</td>\n",
       "      <td>NTT DATA Business Solutions Private Limited</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Urgent Job Opening For AI Practitioner - Data ...</td>\n",
       "      <td>New Delhi, Kochi/Cochin, Bangalore/Bengaluru, ...</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>11-20 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Opening_ Data Scientist_ Pelatro Solutions</td>\n",
       "      <td>Delhi / NCR, Kolkata, Hyderabad/Secunderabad, ...</td>\n",
       "      <td>Pelatro Solutions</td>\n",
       "      <td>8-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New Delhi, Pune, Gurgaon/Gurugram, Bangalore/B...</td>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Forecasting Analyst/ Data Scientist (US Client)</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru\\n(WFH du...</td>\n",
       "      <td>Concentrix</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Affine- Hiring For Data Science - Work from Home</td>\n",
       "      <td>Delhi / NCR, Kolkata, Hyderabad/Secunderabad, ...</td>\n",
       "      <td>Affine</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Looking For Data Scientists</td>\n",
       "      <td>Delhi / NCR, Noida, Pune, Gurgaon/Gurugram, Ba...</td>\n",
       "      <td>Absolutdata</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                   Analystics & Modeling Specialist   \n",
       "1     Data scientist _Tata Consultancy Services(Tcs)   \n",
       "2  Job||Job Opening For AI Technologist - Data Sc...   \n",
       "3  Hiring For DATA Scientist @ NTT DATA Business ...   \n",
       "4  Urgent Job Opening For AI Practitioner - Data ...   \n",
       "5         Opening_ Data Scientist_ Pelatro Solutions   \n",
       "6                                     Data Scientist   \n",
       "7    Forecasting Analyst/ Data Scientist (US Client)   \n",
       "8   Affine- Hiring For Data Science - Work from Home   \n",
       "9                        Looking For Data Scientists   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...   \n",
       "1  New Delhi, Kochi/Cochin, Indore, Hyderabad/Sec...   \n",
       "2  New Delhi, Hyderabad/Secunderabad, Pune, Chenn...   \n",
       "3  Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...   \n",
       "4  New Delhi, Kochi/Cochin, Bangalore/Bengaluru, ...   \n",
       "5  Delhi / NCR, Kolkata, Hyderabad/Secunderabad, ...   \n",
       "6  New Delhi, Pune, Gurgaon/Gurugram, Bangalore/B...   \n",
       "7  Gurgaon/Gurugram, Bangalore/Bengaluru\\n(WFH du...   \n",
       "8  Delhi / NCR, Kolkata, Hyderabad/Secunderabad, ...   \n",
       "9  Delhi / NCR, Noida, Pune, Gurgaon/Gurugram, Ba...   \n",
       "\n",
       "                                  Company Name Experience Required  \n",
       "0                                    Accenture             6-8 Yrs  \n",
       "1              TATA CONSULTANCY SERVICES (TCS)            9-14 Yrs  \n",
       "2                                        Wipro            5-10 Yrs  \n",
       "3  NTT DATA Business Solutions Private Limited             4-9 Yrs  \n",
       "4                                        Wipro           11-20 Yrs  \n",
       "5                            Pelatro Solutions            8-12 Yrs  \n",
       "6                                ZS Associates             5-8 Yrs  \n",
       "7                                   Concentrix             3-8 Yrs  \n",
       "8                                       Affine             4-7 Yrs  \n",
       "9                                  Absolutdata            7-12 Yrs  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Job Title':job_title,'Job Location':job_location,'Company Name':company_name,'Experience Required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4048776",
   "metadata": {},
   "source": [
    "# Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "\n",
    "1.Brand\n",
    "2.Product Description\n",
    "3.Price\n",
    "\n",
    "To scrape the data you have to go through following steps:\n",
    "\n",
    "1.Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2.Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon\n",
    "3.After that you will reach to the page having a lot of sunglasses. From this page you can scrap the required data as usual.\n",
    "4.After scraping data from the first page, go to the “Next” Button at the bottom other page , then click on it.\n",
    "5.Now scrape data from this page as usual\n",
    "6.Repeat this until you get data for 100 sunglasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "7396cd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "b07a67c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"http://www.flipkart.com/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "50c560f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "product=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "product.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "99c8ba04",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"_213eRC\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "a461f0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "820cdb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "for i in brand_tags[0:100]:\n",
    "    brnd=i.text\n",
    "    brand.append(brnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "cd20c676",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_tags=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "for i in price_tags[0:100]:\n",
    "    Rs=i.text\n",
    "    price.append(Rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "ad3b0a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sunglasses=pd.DataFrame({'Brand':brand,\"Price\":price})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "4c2940e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>john jacobs</td>\n",
       "      <td>₹3,325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>₹949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>₹298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PHENOMENAL</td>\n",
       "      <td>₹252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>₹283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>₹211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>₹949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>New Specs</td>\n",
       "      <td>₹265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>₹949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹1,169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RM Collection</td>\n",
       "      <td>₹190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>₹1,533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Dadlace</td>\n",
       "      <td>₹169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RM Collection</td>\n",
       "      <td>₹210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LIZA ANGEL</td>\n",
       "      <td>₹179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>₹849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>New Specs</td>\n",
       "      <td>₹207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>₹474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>₹198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>₹949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SHAAH COLLECTIONS</td>\n",
       "      <td>₹195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>IZAAN MART</td>\n",
       "      <td>₹290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>john jacobs</td>\n",
       "      <td>₹2,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Lee Topper</td>\n",
       "      <td>₹249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Dadlace</td>\n",
       "      <td>₹149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>₹999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>RM Collection</td>\n",
       "      <td>₹310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>RM Collection</td>\n",
       "      <td>₹235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Lee Topper</td>\n",
       "      <td>₹299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>₹949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>₹259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Sewell</td>\n",
       "      <td>₹265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>₹749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Brand   Price\n",
       "0         john jacobs  ₹3,325\n",
       "1       VINCENT CHASE    ₹949\n",
       "2            Fastrack    ₹799\n",
       "3           Elligator    ₹298\n",
       "4          PHENOMENAL    ₹252\n",
       "5              SUNBEE    ₹283\n",
       "6                SRPM    ₹211\n",
       "7       VINCENT CHASE    ₹949\n",
       "8           New Specs    ₹265\n",
       "9            Fastrack    ₹639\n",
       "10             PIRASO    ₹279\n",
       "11      VINCENT CHASE    ₹949\n",
       "12           Fastrack  ₹1,169\n",
       "13             PIRASO    ₹359\n",
       "14      RM Collection    ₹190\n",
       "15      VINCENT CHASE  ₹1,533\n",
       "16            Dadlace    ₹169\n",
       "17      RM Collection    ₹210\n",
       "18         LIZA ANGEL    ₹179\n",
       "19      VINCENT CHASE    ₹849\n",
       "20          New Specs    ₹207\n",
       "21     ROZZETTA CRAFT    ₹474\n",
       "22              NuVew    ₹198\n",
       "23      VINCENT CHASE    ₹949\n",
       "24  SHAAH COLLECTIONS    ₹195\n",
       "25             PIRASO    ₹279\n",
       "26         IZAAN MART    ₹290\n",
       "27        john jacobs  ₹2,500\n",
       "28           Fastrack    ₹719\n",
       "29         Lee Topper    ₹249\n",
       "30            Dadlace    ₹149\n",
       "31      VINCENT CHASE    ₹999\n",
       "32      RM Collection    ₹310\n",
       "33      RM Collection    ₹235\n",
       "34         Lee Topper    ₹299\n",
       "35      VINCENT CHASE    ₹949\n",
       "36             PIRASO    ₹279\n",
       "37             SUNBEE    ₹259\n",
       "38             Sewell    ₹265\n",
       "39      VINCENT CHASE    ₹749"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sunglasses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac78c557",
   "metadata": {},
   "source": [
    "# Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. This task will be done in following steps:\n",
    "\n",
    "1.First get the webpage https://www.flipkart.com/\n",
    "2.Enter “iphone 11” in “Search” field .\n",
    "3.Then click the search button.\n",
    "\n",
    "you have to scrape the tick marked attributes.These are:\n",
    "\n",
    "4.Rating\n",
    "5.Review summary\n",
    "6.Full review\n",
    "7.You have to scrape this data for first 100 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "id": "d7c39ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "id": "206c5caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"http://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "id": "014dcbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Apple=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "Apple.send_keys('iphone11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "id": "de947fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "id": "0941bb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "product=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[2]/div/div/div/a/div[2]/div[1]/div[1]\")\n",
    "product.click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "id": "782a2a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating=[]\n",
    "review_summary=[]\n",
    "full_review=[] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "id": "2b1d765a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in rating_tags[0:10]:\n",
    "    RA=i.text\n",
    "    rating.append(RA) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "id": "5885e9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_tags=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "for i in review_tags[0:10]:\n",
    "    Rev=i.text\n",
    "    review_summary.append(Rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "id": "096831d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewfull_tags=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "for i in reviewfull_tags[0:10]:\n",
    "    FR=i.text\n",
    "    full_review.append(FR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "id": "3aa4583d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n"
     ]
    }
   ],
   "source": [
    "print(len(rating),len(review_summary),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "id": "07092db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Rating, Review Summary, Full Review]\n",
       "Index: []"
      ]
     },
     "execution_count": 826,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Rating':rating,'Review Summary':review_summary,'Full Review':full_review})\n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbee304f",
   "metadata": {},
   "source": [
    "# Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field. You have to scrape 4 attributes of each sneaker:\n",
    "\n",
    "1.Brand\n",
    "2.Product Description\n",
    "3.Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "918fdfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "3804f0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.flipkart.com/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "76738fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "findp=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "findp.click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "0a5dd210",
   "metadata": {},
   "outputs": [],
   "source": [
    "product=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "product.send_keys('Sneakers') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "615f6d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "8ab357b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=[]\n",
    "price=[] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "78819931",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "for i in brand_tags[0:120]:\n",
    "    brnd=i.text\n",
    "    brand.append(brnd) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "629813a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_tags=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "for i in price_tags[0:120]:\n",
    "    Prc=i.text\n",
    "    price.append(Prc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "58f6b7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 80\n"
     ]
    }
   ],
   "source": [
    "print(len(brand),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "3a2a5733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>₹599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ELEVAR</td>\n",
       "      <td>₹5,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DUCATI</td>\n",
       "      <td>₹1,413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>₹2,217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>₹374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>pollachief</td>\n",
       "      <td>₹598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>CLYMB</td>\n",
       "      <td>₹463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>AMICO</td>\n",
       "      <td>₹426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>DUCATI</td>\n",
       "      <td>₹1,399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>ACTION</td>\n",
       "      <td>₹902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand   Price\n",
       "0   Robbie jones    ₹599\n",
       "1         ELEVAR  ₹5,490\n",
       "2         DUCATI  ₹1,413\n",
       "3           PUMA  ₹2,217\n",
       "4       Magnolia    ₹374\n",
       "..           ...     ...\n",
       "75    pollachief    ₹598\n",
       "76         CLYMB    ₹463\n",
       "77         AMICO    ₹426\n",
       "78        DUCATI  ₹1,399\n",
       "79        ACTION    ₹902\n",
       "\n",
       "[80 rows x 2 columns]"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sneakers=pd.DataFrame({'Brand':brand,\"Price\":price})\n",
    "Sneakers[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab7f2a5",
   "metadata": {},
   "source": [
    "# # Q7: Go to the link - https://www.myntra.com/shoes Set second Price filter and Color filter to “Black”, And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe as shown in the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "99147259",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "c2488dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.myntra.com/shoes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "c100bbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "price=driver.find_element(By.XPATH,\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label\")\n",
    "price.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "0511db1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "colour=driver.find_element(By.XPATH,\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/span[1]\")\n",
    "colour.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "ea192125",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=[]\n",
    "price=[]\n",
    "product_description=[] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "d4c05d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_tags=driver.find_elements(By.XPATH,'//h3[@class=\"product-brand\"]')\n",
    "for i in brand_tags[0:100]:\n",
    "    brnd=i.text\n",
    "    brand.append(brnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "5681acc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_tags=driver.find_elements(By.XPATH,'//div[@class=\"product-price\"]')\n",
    "for i in price_tags[0:100]:\n",
    "    Prc=i.text\n",
    "    price.append(Prc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "640688df",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_tags=driver.find_elements(By.XPATH,'//h4[@class=\"product-product\"]')\n",
    "for i in product_tags[0:100]:\n",
    "    des=i.text\n",
    "    product_description.append(des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "ce1cf2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(brand),len(price),len(product_description)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "92986da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 7880Rs. 8295(5% OFF)</td>\n",
       "      <td>Men Winflo 8 Running Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 7880Rs. 8295(5% OFF)</td>\n",
       "      <td>Men ZOOM WINFLO8 Running Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 10795</td>\n",
       "      <td>Men Colourblocked Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 7880Rs. 8295(5% OFF)</td>\n",
       "      <td>Men Zoom Winflo 8 Running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Rs. 8099Rs. 8999(10% OFF)</td>\n",
       "      <td>Men Leather Slip-On Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 11045Rs. 12995(15% OFF)</td>\n",
       "      <td>Women Air Max Pre-Day Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Rs. 6999</td>\n",
       "      <td>Men Lockdown 5 Basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 8595</td>\n",
       "      <td>Men Leather Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Rs. 7199Rs. 8999(20% OFF)</td>\n",
       "      <td>Men Go Walk Arch Fit Walking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Clarks</td>\n",
       "      <td>Rs. 7999</td>\n",
       "      <td>Men Solid Leather Derbys Shoes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand                        Price             Product Description\n",
       "0           Nike     Rs. 7880Rs. 8295(5% OFF)      Men Winflo 8 Running Shoes\n",
       "1           Nike     Rs. 7880Rs. 8295(5% OFF)  Men ZOOM WINFLO8 Running Shoes\n",
       "2           Nike                    Rs. 10795      Men Colourblocked Sneakers\n",
       "3           Nike     Rs. 7880Rs. 8295(5% OFF)       Men Zoom Winflo 8 Running\n",
       "4   Hush Puppies    Rs. 8099Rs. 8999(10% OFF)    Men Leather Slip-On Sneakers\n",
       "..           ...                          ...                             ...\n",
       "95          Nike  Rs. 11045Rs. 12995(15% OFF)  Women Air Max Pre-Day Sneakers\n",
       "96  UNDER ARMOUR                     Rs. 6999       Men Lockdown 5 Basketball\n",
       "97          Nike                     Rs. 8595            Men Leather Sneakers\n",
       "98      Skechers    Rs. 7199Rs. 8999(20% OFF)    Men Go Walk Arch Fit Walking\n",
       "99        Clarks                     Rs. 7999  Men Solid Leather Derbys Shoes\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Shoes=pd.DataFrame({'Brand':brand,'Price':price,'Product Description':product_description})\n",
    "Shoes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00958fb6",
   "metadata": {},
   "source": [
    "# Q8: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” as shown in the below image: After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "\n",
    "1.Title\n",
    "2.Ratings\n",
    "3.Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "id": "7608a631",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "id": "665282b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.amazon.in/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "id": "57e78dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "product=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "product.send_keys('Laptops') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "id": "9636ebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "id": "851b8c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "CPU=driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[4]/li[12]/span/a\")\n",
    "CPU.click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "id": "a71b9cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "title=[]\n",
    "rating=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "id": "1238e42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags=driver.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    tit=i.text\n",
    "    title.append(tit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "id": "6b159398",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_tags=driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "for i in price_tags[0:10]:\n",
    "    Prc=i.text\n",
    "    price.append(Prc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "id": "2bbf3a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[3]/div/span')\n",
    "for i in rating_tags[0:10]:\n",
    "    Rtng=i.text\n",
    "    rating.append(Rtng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "id": "a6bc47a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(rating),len(title),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "id": "c9a71636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Customer Reviews</td>\n",
       "      <td>Samsung Galaxy Book2 Intel 12th Gen core i7 39...</td>\n",
       "      <td>79,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Customer Reviews</td>\n",
       "      <td>Samsung Galaxy Book2 360 Intel 12th Gen i7 Evo...</td>\n",
       "      <td>97,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Customer Reviews</td>\n",
       "      <td>Samsung Galaxy Book2 Intel 12th Gen core i7 39...</td>\n",
       "      <td>79,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Customer Reviews</td>\n",
       "      <td>HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...</td>\n",
       "      <td>87,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Customer Reviews</td>\n",
       "      <td>ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...</td>\n",
       "      <td>57,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Customer Reviews</td>\n",
       "      <td>ASUS TUF Gaming F17 (2022), 17.3-inch (43.94 c...</td>\n",
       "      <td>1,29,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Customer Reviews</td>\n",
       "      <td>ASUS TUF Gaming F15 (2022), 15.6-inch (39.62 c...</td>\n",
       "      <td>1,07,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Customer Reviews</td>\n",
       "      <td>Lenovo ThinkPad E14 Intel Core i7 11th Gen 14-...</td>\n",
       "      <td>94,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Customer Reviews</td>\n",
       "      <td>ASUS TUF Gaming F15 (2022), 15.6\" (39.62 cms) ...</td>\n",
       "      <td>1,07,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Customer Reviews</td>\n",
       "      <td>HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...</td>\n",
       "      <td>89,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Rating                                              Title  \\\n",
       "0  Customer Reviews  Samsung Galaxy Book2 Intel 12th Gen core i7 39...   \n",
       "1  Customer Reviews  Samsung Galaxy Book2 360 Intel 12th Gen i7 Evo...   \n",
       "2  Customer Reviews  Samsung Galaxy Book2 Intel 12th Gen core i7 39...   \n",
       "3  Customer Reviews  HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...   \n",
       "4  Customer Reviews  ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...   \n",
       "5  Customer Reviews  ASUS TUF Gaming F17 (2022), 17.3-inch (43.94 c...   \n",
       "6  Customer Reviews  ASUS TUF Gaming F15 (2022), 15.6-inch (39.62 c...   \n",
       "7  Customer Reviews  Lenovo ThinkPad E14 Intel Core i7 11th Gen 14-...   \n",
       "8  Customer Reviews  ASUS TUF Gaming F15 (2022), 15.6\" (39.62 cms) ...   \n",
       "9  Customer Reviews  HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...   \n",
       "\n",
       "      Price  \n",
       "0    79,490  \n",
       "1    97,990  \n",
       "2    79,490  \n",
       "3    87,990  \n",
       "4    57,990  \n",
       "5  1,29,990  \n",
       "6  1,07,990  \n",
       "7    94,990  \n",
       "8  1,07,990  \n",
       "9    89,990  "
      ]
     },
     "execution_count": 796,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptop=pd.DataFrame({'Rating':rating[0:10],'Title':title,'Price':price})\n",
    "laptop[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255f0075",
   "metadata": {},
   "source": [
    "# Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida location. You have to scrape company name, No. of days ago when job was posted, Rating of the company. This task will be done in following steps:\n",
    "\n",
    "1.First get the webpage https://www.ambitionbox.com/\n",
    "2.Click on the Job option\n",
    "3.After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter “Data Scientist” and click on search button.\n",
    "4.You will reach to the following web page click on location and in place of “Search location” enter “Noida” and select location “Noida”.\n",
    "5.Then scrape the data for the first 10 jobs results you get on the above shown page.\n",
    "6.Finally create a dataframe of the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "2cbad537",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "a1317311",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.ambitionbox.com/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "5cc365fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs=driver.find_element(By.XPATH,\"/html/body/div[1]/nav[2]/div/ul/li[5]/a\")\n",
    "jobs.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "d0f7f7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.XPATH,\"/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/div/span/input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "1c2b539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,\"/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/button\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "4c3ab5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "select=driver.find_element(By.XPATH,\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[1]/i\")\n",
    "select.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "421c1b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input\")\n",
    "location.send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "856331f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "GrN=driver.find_element(By.XPATH,\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label\")\n",
    "GrN.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "b3555f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name=[]\n",
    "days=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "7973ecb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_tags=driver.find_elements(By.XPATH,'//span[@class=\"body-small-l\"]')\n",
    "for i in days_tags[0:10]:\n",
    "    dy=i.text\n",
    "    days.append(dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "62dbed42",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_tags=driver.find_elements(By.XPATH,'//div[@class=\"body-small\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    cmpny=i.text\n",
    "    company_name.append(cmpny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "220b314b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No. of days ago</th>\n",
       "      <th>Company Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10d ago</td>\n",
       "      <td>Walmart\\nData Scientist Salary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>via naukri.com</td>\n",
       "      <td>Ab Inbev\\nData Scientist Salary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3d ago</td>\n",
       "      <td>Optum\\nData Scientist Salary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>via naukri.com</td>\n",
       "      <td>ZS\\nData Scientist Salary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5d ago</td>\n",
       "      <td>Fractal Analytics\\nData Scientist Salary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>via iimjobs.com</td>\n",
       "      <td>Tiger Analytics\\nData Scientist Salary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20d ago</td>\n",
       "      <td>Legato Health Technologies\\nData Scientist Salary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>via naukri.com</td>\n",
       "      <td>Tredence\\nData Scientist Salary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13d ago</td>\n",
       "      <td>UnitedHealth\\nData Scientist Salary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>via naukri.com</td>\n",
       "      <td>Ford Motor\\nData Scientist Salary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No. of days ago                                       Company Name\n",
       "0          10d ago                     Walmart\\nData Scientist Salary\n",
       "1   via naukri.com                    Ab Inbev\\nData Scientist Salary\n",
       "2           3d ago                       Optum\\nData Scientist Salary\n",
       "3   via naukri.com                          ZS\\nData Scientist Salary\n",
       "4           5d ago           Fractal Analytics\\nData Scientist Salary\n",
       "5  via iimjobs.com             Tiger Analytics\\nData Scientist Salary\n",
       "6          20d ago  Legato Health Technologies\\nData Scientist Salary\n",
       "7   via naukri.com                    Tredence\\nData Scientist Salary\n",
       "8          13d ago                UnitedHealth\\nData Scientist Salary\n",
       "9   via naukri.com                  Ford Motor\\nData Scientist Salary"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Jobs=pd.DataFrame({'No. of days ago':days[0:10],'Company Name':company_name[0:10]})\n",
    "Jobs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe014934",
   "metadata": {},
   "source": [
    "# Q10: Write a python program to scrape the salary data for Data Scientist designation. You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary. The above task will be, done as shown in the below steps:\n",
    "\n",
    "1.First get the webpage https://www.ambitionbox.com/\n",
    "2.click on the salaries option\n",
    "3.After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and then click on “Data   Scientist”. You have to scrape the data ticked in the above image.\n",
    "4.Scrape the data for the first 10 companies. Scrape the company name, total salary record, average salary, minimum salary, maximum salary, experience required.\n",
    "5.Store the data in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "fab2048c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "323fc0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.ambitionbox.com/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "0f19f74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Select=driver.find_element(By.XPATH,\"/html/body/div[1]/nav[2]/div/ul/li[3]/a\")\n",
    "Select.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "b9ac1e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsalary=driver.find_element(By.XPATH,\"/html/body/div[1]/nav[2]/div/ul/li[3]/div/ul/li[1]/div\")\n",
    "bsalary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "cca89d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.XPATH,\"/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "d09bc8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dclick=driver.find_element(By.XPATH,\"/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/div/div/div[1]\")\n",
    "dclick.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "id": "9c7e8f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Experience_Required=[]\n",
    "company_name=[]\n",
    "Total_Salary=[]\n",
    "Average=[]\n",
    "Minimum=[]\n",
    "Maximum=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "id": "9e9216c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_tags=driver.find_elements(By.XPATH,'//div[@class=\"sbold-list-header\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    Experience_Required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "id": "c9558bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_tags=driver.find_elements(By.XPATH,'//div[@class=\"company-info\"]//a')\n",
    "for i in company_tags[0:10]:\n",
    "    com=i.text\n",
    "    company_name.append(com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "id": "ee2934c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_tags=driver.find_elements(By.XPATH,'//p[@class=\"averageCtc\"]')\n",
    "for i in avg_tags[0:10]:\n",
    "    avg=i.text\n",
    "    Average.append(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "id": "fa994916",
   "metadata": {},
   "outputs": [],
   "source": [
    "TSR_tags=driver.find_elements(By.XPATH,'//span[@class=\"datapoints\"]')\n",
    "for i in TSR_tags[0:10]:\n",
    "    TotalR=i.text\n",
    "    Total_Salary.append(TotalR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "id": "dbae73b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_tags=driver.find_elements(By.XPATH,\"//html/body/div/div/div/div[2]/div/div/div/div[2]/div/ul/li[5]\")\n",
    "for i in min_tags[0:10]:\n",
    "    minm=i.text\n",
    "    Minimum.append(minm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "id": "be9d2bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tags=driver.find_elements(By.XPATH,'//div[@class=\"value body-medium\"]')\n",
    "for i in max_tags[0:10]:\n",
    "    maxm=i.text\n",
    "    Maximum.append(maxm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "id": "1ca5221c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(Experience_Required),len(company_name),len(Total_Salary),len(Minimum),len(Maximum),len(Average))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "id": "de635e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "      <th>Total Salary Record</th>\n",
       "      <th>Maximum Salary</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Average Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart\\nData Scientist Salary</td>\n",
       "      <td>3-4 yrs experience (based on 22 salaries)</td>\n",
       "      <td>(based on 22 salaries)</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>Salaries</td>\n",
       "      <td>₹ 31.7L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab Inbev\\nData Scientist Salary</td>\n",
       "      <td>2-4 yrs experience (based on 53 salaries)</td>\n",
       "      <td>(based on 53 salaries)</td>\n",
       "      <td>₹ 45.0L</td>\n",
       "      <td>Salaries</td>\n",
       "      <td>₹ 19.7L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Optum\\nData Scientist Salary</td>\n",
       "      <td>2-4 yrs experience (based on 48 salaries)</td>\n",
       "      <td>(based on 48 salaries)</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>Salaries</td>\n",
       "      <td>₹ 16.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZS\\nData Scientist Salary</td>\n",
       "      <td>1-2 yrs experience (based on 33 salaries)</td>\n",
       "      <td>(based on 33 salaries)</td>\n",
       "      <td>₹ 25.5L</td>\n",
       "      <td>Salaries</td>\n",
       "      <td>₹ 15.7L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fractal Analytics\\nData Scientist Salary</td>\n",
       "      <td>2-4 yrs experience (based on 109 salaries)</td>\n",
       "      <td>(based on 109 salaries)</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>Salaries</td>\n",
       "      <td>₹ 15.2L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tiger Analytics\\nData Scientist Salary</td>\n",
       "      <td>2-4 yrs experience (based on 65 salaries)</td>\n",
       "      <td>(based on 65 salaries)</td>\n",
       "      <td>₹ 22.6L</td>\n",
       "      <td>Salaries</td>\n",
       "      <td>₹ 14.7L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Legato Health Technologies\\nData Scientist Salary</td>\n",
       "      <td>4 yrs experience (based on 11 salaries)</td>\n",
       "      <td>(based on 11 salaries)</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>Salaries</td>\n",
       "      <td>₹ 14.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tredence\\nData Scientist Salary</td>\n",
       "      <td>3 yrs experience (based on 12 salaries)</td>\n",
       "      <td>(based on 12 salaries)</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "      <td>Salaries</td>\n",
       "      <td>₹ 14.1L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UnitedHealth\\nData Scientist Salary</td>\n",
       "      <td>2-4 yrs experience (based on 91 salaries)</td>\n",
       "      <td>(based on 91 salaries)</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>Salaries</td>\n",
       "      <td>₹ 13.6L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ford Motor\\nData Scientist Salary</td>\n",
       "      <td>3-4 yrs experience (based on 21 salaries)</td>\n",
       "      <td>(based on 21 salaries)</td>\n",
       "      <td>₹ 23.0L</td>\n",
       "      <td>Salaries</td>\n",
       "      <td>₹ 13.5L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Company Name  \\\n",
       "0                     Walmart\\nData Scientist Salary   \n",
       "1                    Ab Inbev\\nData Scientist Salary   \n",
       "2                       Optum\\nData Scientist Salary   \n",
       "3                          ZS\\nData Scientist Salary   \n",
       "4           Fractal Analytics\\nData Scientist Salary   \n",
       "5             Tiger Analytics\\nData Scientist Salary   \n",
       "6  Legato Health Technologies\\nData Scientist Salary   \n",
       "7                    Tredence\\nData Scientist Salary   \n",
       "8                UnitedHealth\\nData Scientist Salary   \n",
       "9                  Ford Motor\\nData Scientist Salary   \n",
       "\n",
       "                          Experience Required      Total Salary Record  \\\n",
       "0   3-4 yrs experience (based on 22 salaries)   (based on 22 salaries)   \n",
       "1   2-4 yrs experience (based on 53 salaries)   (based on 53 salaries)   \n",
       "2   2-4 yrs experience (based on 48 salaries)   (based on 48 salaries)   \n",
       "3   1-2 yrs experience (based on 33 salaries)   (based on 33 salaries)   \n",
       "4  2-4 yrs experience (based on 109 salaries)  (based on 109 salaries)   \n",
       "5   2-4 yrs experience (based on 65 salaries)   (based on 65 salaries)   \n",
       "6     4 yrs experience (based on 11 salaries)   (based on 11 salaries)   \n",
       "7     3 yrs experience (based on 12 salaries)   (based on 12 salaries)   \n",
       "8   2-4 yrs experience (based on 91 salaries)   (based on 91 salaries)   \n",
       "9   3-4 yrs experience (based on 21 salaries)   (based on 21 salaries)   \n",
       "\n",
       "  Maximum Salary Minimum Salary Average Salary  \n",
       "0        ₹ 25.0L       Salaries        ₹ 31.7L  \n",
       "1        ₹ 45.0L       Salaries        ₹ 19.7L  \n",
       "2        ₹ 15.0L       Salaries        ₹ 16.5L  \n",
       "3        ₹ 25.5L       Salaries        ₹ 15.7L  \n",
       "4        ₹ 11.0L       Salaries        ₹ 15.2L  \n",
       "5        ₹ 22.6L       Salaries        ₹ 14.7L  \n",
       "6        ₹ 11.0L       Salaries        ₹ 14.5L  \n",
       "7        ₹ 22.0L       Salaries        ₹ 14.1L  \n",
       "8         ₹ 9.0L       Salaries        ₹ 13.6L  \n",
       "9        ₹ 23.0L       Salaries        ₹ 13.5L  "
      ]
     },
     "execution_count": 758,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Records=pd.DataFrame({'Company Name':company_name[0:10],\"Experience Required\":Experience_Required,\"Total Salary Record\":Total_Salary,\"Maximum Salary\":Maximum[0:10], \"Minimum Salary\":Minimum[0:10],\"Average Salary\":Average})\n",
    "Records[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90918b1",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "id": "b45c23d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b15548c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae8168b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
